---
layout: post
title: "TDC_이미지분류"
date: 2021-03-15
author: 단우아범
categories: "딥러닝"
tags:	
cover: "/assets/instacode.png"
---

이미지 분류기는 3번 문제인데, 총 4가지 문제가 자주 출제됨  
모두다 기본적으로는,  
 - import  
 - 전처리  
 - 모델링  
 - 컴파일  
 - 학습  

유형은 구체적으로 2개씩 나눌 수 있는데  

# 1. Type A  
 - ImageDataGenerator를 활용한 이미지 분류 문제  
 - IDG란 이미지를 상하, 좌우 반전 등으로 복제함  
 - Training root 폴더, Test root 폴더를 지정해서 그 폴더에 복제하여 사용함  
 - 
    ```
    # 전처리 
    
    TRAINING_DIR = 'tmp/horse-or-human/'
    VALIDATION_DIR = 'tmp/validation-horse-or-human/'

    * `rescale`: 이미지의 픽셀 값을 조정
    * `rotation_range`: 이미지 회전
    * `width_shift_range`: 가로 방향으로 이동
    * `height_shift_range`: 세로 방향으로 이동
    * `shear_range`: 이미지 굴절
    * `zoom_range`: 이미지 확대
    * `horizontal_flip`: 횡 방향으로 이미지 반전
    * `fill_mode`: 이미지를 이동이나 굴절시켰을 때 빈 픽셀 값에 대하여 값을 채우는 방식
    * `validation_split`: validation set의 구성 비율

    # IDG
    training_datagen = ImageDataGenerator(
      rescale=1. / 255,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest', 
      validation_split=0.2 # 이걸 해주면 traing, validation을 알아서 나눠서 IDG함
      )

    # Make generator
    training_generator = training_datagen.flow_from_directory(TRAINING_DIR, 
                                                          batch_size=128, 
                                                          target_size=(150, 150), 
                                                          class_mode='categorical', 
                                                          subset='training', # train
                                                         )

    validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, 
                                                          batch_size=128, 
                                                          target_size=(150, 150), 
                                                          class_mode='categorical',
                                                          subset='validation', # val
                                                          )
                                                          
    # 모델링
    # 컴파일
    # fit    
    ```

# 2. Type B  
 - tfds를 활용한 이미지 분류 문제  
 - 해결 Step  
    ```
    # 데이터 업로드
    dataset_name = 'cats_vs_dogs'

    # 처음 80%의 데이터만 사용
    train_dataset = tfds.load(name=dataset_name, split='train[:80%]')

    # 최근 20%의 데이터만 사용
    valid_dataset = tfds.load(name=dataset_name, split='train[80%:]')


    #전처리
    1. 이미지 정규화 (Normalization)
    2. 이미지 사이즈 맞추기: (224 X 224)
    3. image(x), label(y)를 분할

    def preprocess(data):
      # x, y 데이터를 정의합니다.
      x = data['image']
      y = data['label']
      # image 정규화(Normalization)
      x = tf.cast(x, tf.float32) / 255.0
      # 사이즈를 (224, 224)로 변환합니다.
      x = tf.image.resize(x, size=(224, 224))
      # x, y  데이터를 return 합니다.
      return x, y

    batch_size=32
    train_data = train_dataset.map(preprocess).batch(batch_size)
    valid_data = valid_dataset.map(preprocess).batch(batch_size)

    #모델링

    이제 Modeling을 할 차례입니다.

    `Sequential` 모델 안에서 층을 깊게 쌓아 올려 주면 됩니다.

    1. `input_shape`는 (height, width, color_channel)입니다. cats vs dogs 문제에서는 (224, 224, 3) 이 됩니다.
    2. 깊은 출력층과 더 많은 Layer를 쌓습니다.
    3. Dense Layer에 `activation='relu'`를 적용합니다.
    4. 분류(Classification)의 마지막 층의 출력 숫자는 분류하고자 하는 클래스 갯수와 **같아야** 합니다.

    model = Sequential([
      Conv2D(64, (3, 3), input_shape=(224, 224, 3), activation='relu'),
      MaxPooling2D(2, 2),
      Conv2D(64, (3, 3), activation='relu'),
      MaxPooling2D(2, 2),
      Conv2D(128, (3, 3), activation='relu'),
      MaxPooling2D(2, 2),
      Conv2D(128, (3, 3), activation='relu'),
      MaxPooling2D(2, 2),
      Conv2D(256, (3, 3), activation='relu'),
      MaxPooling2D(2, 2),
      Flatten(),
      Dropout(0.5),
      Dense(512, activation='relu'),
      Dense(128, activation='relu'),
      Dense(2, activation='softmax'),
    ])


    #컴파일
    1. `optimizer`는 가장 최적화가 잘되는 알고리즘인 'adam'을 사용합니다.
    2. `loss`설정
    * 출력층 activation이 `sigmoid` 인 경우: `binary_crossentropy`
    * 출력층 activation이 `softmax` 인 경우: 
      * 원핫인코딩(O): `categorical_crossentropy`
      * 원핫인코딩(X): `sparse_categorical_crossentropy`)
    3. `metrics`를 'acc' 혹은 'accuracy'로 지정하면, 학습시 정확도를 모니터링 할 수 있습니다.

    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])

    ```

