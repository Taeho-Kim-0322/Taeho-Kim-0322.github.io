---
layout: post
title: "TDC_이미지분류"
date: 2021-03-15
author: 단우아범
categories: "딥러닝"
tags:	
cover: "/assets/instacode.png"
---

이미지 분류기는 3번 문제인데, 총 4가지 문제가 자주 출제됨  
2개씩 나눌 수 있는데  

# 1. Type A  
 - ImageDataGenerator를 활용한 이미지 분류 문제  
 - IDG란 이미지를 상하, 좌우 반전 등으로 복제함  
 - Training root 폴더, Test root 폴더를 지정해서 그 폴더에 복제하여 사용함  
 - 
  ```
  TRAINING_DIR = 'tmp/horse-or-human/'
  VALIDATION_DIR = 'tmp/validation-horse-or-human/'
  
  * `rescale`: 이미지의 픽셀 값을 조정
  * `rotation_range`: 이미지 회전
  * `width_shift_range`: 가로 방향으로 이동
  * `height_shift_range`: 세로 방향으로 이동
  * `shear_range`: 이미지 굴절
  * `zoom_range`: 이미지 확대
  * `horizontal_flip`: 횡 방향으로 이미지 반전
  * `fill_mode`: 이미지를 이동이나 굴절시켰을 때 빈 픽셀 값에 대하여 값을 채우는 방식
  * `validation_split`: validation set의 구성 비율
  
  # IDG
  training_datagen = ImageDataGenerator(
    rescale=1. / 255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest', 
    validation_split=0.2 # 이걸 해주면 traing, validation을 알아서 나눠서 IDG함
    )
    
  # Make generator
  training_generator = training_datagen.flow_from_directory(TRAINING_DIR, 
                                                        batch_size=128, 
                                                        target_size=(150, 150), 
                                                        class_mode='categorical', 
                                                        subset='training', # train
                                                       )
                                                       
  validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, 
                                                        batch_size=128, 
                                                        target_size=(150, 150), 
                                                        class_mode='categorical',
                                                        subset='validation', # val
                                                        )

  ```
 - Step

# 2. Type B  
 - tfds를 활용한 이미지 분류 문제  
 - 해결 Step  
  ```
  # 데이터 업로드
  dataset_name = 'cats_vs_dogs'

  # 처음 80%의 데이터만 사용
  train_dataset = tfds.load(name=dataset_name, split='train[:80%]')

  # 최근 20%의 데이터만 사용
  valid_dataset = tfds.load(name=dataset_name, split='train[80%:]')
  
  
  #전처리
  1. 이미지 정규화 (Normalization)
  2. 이미지 사이즈 맞추기: (224 X 224)
  3. image(x), label(y)를 분할
  
  def preprocess(data):
    # x, y 데이터를 정의합니다.
    x = data['image']
    y = data['label']
    # image 정규화(Normalization)
    x = tf.cast(x, tf.float32) / 255.0
    # 사이즈를 (224, 224)로 변환합니다.
    x = tf.image.resize(x, size=(224, 224))
    # x, y  데이터를 return 합니다.
    return x, y
  
  batch_size=32
  train_data = train_dataset.map(preprocess).batch(batch_size)
  valid_data = valid_dataset.map(preprocess).batch(batch_size)
  
  #모델링
  
  이제 Modeling을 할 차례입니다.

  `Sequential` 모델 안에서 층을 깊게 쌓아 올려 주면 됩니다.

  1. `input_shape`는 (height, width, color_channel)입니다. cats vs dogs 문제에서는 (224, 224, 3) 이 됩니다.
  2. 깊은 출력층과 더 많은 Layer를 쌓습니다.
  3. Dense Layer에 `activation='relu'`를 적용합니다.
  4. 분류(Classification)의 마지막 층의 출력 숫자는 분류하고자 하는 클래스 갯수와 **같아야** 합니다.

  model = Sequential([
    Conv2D(64, (3, 3), input_shape=(224, 224, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(256, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dropout(0.5),
    Dense(512, activation='relu'),
    Dense(128, activation='relu'),
    Dense(2, activation='softmax'),
  ])
  
  
  #컴파일
  1. `optimizer`는 가장 최적화가 잘되는 알고리즘인 'adam'을 사용합니다.
  2. `loss`설정
  * 출력층 activation이 `sigmoid` 인 경우: `binary_crossentropy`
  * 출력층 activation이 `softmax` 인 경우: 
    * 원핫인코딩(O): `categorical_crossentropy`
    * 원핫인코딩(X): `sparse_categorical_crossentropy`)
  3. `metrics`를 'acc' 혹은 'accuracy'로 지정하면, 학습시 정확도를 모니터링 할 수 있습니다.
  
  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])
  
  ```

