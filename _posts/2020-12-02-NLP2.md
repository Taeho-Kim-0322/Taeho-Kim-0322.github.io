---
layout: post
title:  "NLP 2일차 : Attention"
date:   2020-12-02
author: 단우아범
categories: "언어지능"
tags:	
cover:  "/assets/instacode.png"
---

# 2-1 : Seq2Seq 태스크
## 0. Seq2Seq이란?
 - 지금까지 우리는 시퀀스 인풋을 받아 단일 아웃풋(긍/부 등)을 리턴하는 모델을 RNN, CNN을 사용해 확인하였음  
 그런데, 지금부터는 시퀀스를 인풋으로 받아 시퀀스를 아웃풋으로 리턴하는 아키텍처에 대해 알아봄(e.g. 번역기)
 
 
## 1. 번역 태스크를 어떻게 수행할 수 있을까?
  - 영어 문장을 인풋으로 받아 한국어로 번역하는 모델은 어떻게 만들 수 있을까?  
  __인풋으로 들어온 문장의 정보__ 를 잘 모델링하여 __hidden vector__ 에 담아내고, 이 의미에 기반해 토큰을 하나씩 꺼내면 될 것임
  
  - 2개의 RNN을 사용해, 하나는 원본 문장의 정보를 인코딩하는 인코더, 다른 하나는 원본의 의미에 맞는 토큰을 꺼내는 디코더로 활용함
  
  <img src = "https://user-images.githubusercontent.com/59005950/100817785-13f7ba00-348c-11eb-8936-da1a5135b38a.png">  
  인코더 RNN은 입력 시퀀스를 처리해 원본 문장의 의미를 잘 담은 hidden vector를 만들고, 디코더 RNN의 initial hidden state로 토스합니다.  
디코더 RNN은 이 hidden state의 정보와, 디코더 RNN의 인풋의 정보를 처리하여 해당 타임스텝의 토큰을 예측합니다.  
여기서 예측이란, RNN유닛이 리턴한 hidden state를 통해 타겟 언어의 단어사전 크기에 해당하는 확률값 벡터를 만드는 것을 의미합니다.  
이렇게 되면 확률값이 가장 큰 인덱스에 해당하는 토큰이 해당 타임스텝의 예측치가 됩니다. (greedy search)
  
  - 디코더 RNN은 어떤 것을 인풋으로 받아 이러한 기능을 수행할 수 있을까?
  <img src = "https://user-images.githubusercontent.com/59005950/100818042-b152ee00-348c-11eb-8298-cbdd415485c3.png">  
먼저 디코더 RNN은 첫 번째 타임스텝에서 인풋으로 문장의 시작을 알리는 스페셜 토큰(예:<sos>)을 입력받습니다.  
  
  지금부터 번역을 시작할 것이라는 정보를 주는 것이지요.  
이 시그널을 바탕으로 인코더 RNN이 넘겨준 정보(hidden state)를 가공하여 첫 번째 토큰을 디코딩해냅니다.  
위의 그림에서는 <이제>라는 토큰이 디코딩되었습니다.  
두 번째 타임스텝에서는 이전 타임스텝에서 디코딩된 토큰을 인풋으로 받아 hidden state와 가공하여 두 번째 토큰을 디코딩합니다.  
이렇게 이전 타임스텝의 아웃풋을 이번 타임스텝의 인풋으로 사용하는 것을 Input Feeding이라고 부릅니다.  
이 Input Feeding을 사용하면 RNN의 특성상 계속해서 아웃풋을 디코딩해낼 수 있습니다.  
하지만 언젠가는 번역문장이 끝나야 합니다.  
"번역이 끝났다"라는 시그널을 주기 위해, 모델은 번역을 완료하면 <eos>, 즉 "end of sentence"에 해당하는 스페셜 토큰을 디코딩합니다.  
이런 식으로 학습된 모델을 이용해 추론을 하게 되면 우리는 언제 모델이 번역을 완료했는지 알 수 있습니다.  
  
  
  <img src = "https://user-images.githubusercontent.com/59005950/100818047-b2841b00-348c-11eb-9a30-3efcf9c62196.png">  
이렇게 두 개의 RNN을 사용한 Seq2Seq 모델은 하나의 시스템으로 작동합니다.  
인코더 임베딩부터 디코더 아웃풋레이어까지 End-to-End back-propagation을 수행하며 파라미터들이 업데이트됩니다.  
여기서 Loss는 디코더 RNN이 각각의 타입스텝에서 예측한 확률 분포에 대해 sparse_cross_entropy_loss를 계산한 것을 모두 합하여 계산합니다.  
  

## 2. Seq2Seq 모델이 잘 학습될 수 있도록 도와주는 "선생님 알고리즘"
  <img src = "https://user-images.githubusercontent.com/59005950/100818327-3b9b5200-348d-11eb-91e6-6936f84fc16a.png">  
- 즉, 모델이 해당 타임스텝에서 틀린 확률분포를 예측했더라도,  
Teacher forcing 알고리즘을 통해 다음 타임스텝에는 "이전 스텝의 정답 토큰"을 인풋으로 줌  
이런 알고리즘을 통해 Seq2Seq 학습을 더 안정적으로 할 수 있음
  
  
## 3. Seq2Seq 활용 예시
  - 기계번역, 요약, 대화, 코드생성 등 다양한 태스크가 가능함
    
---

# 2-2 : Attention이란?
## 1. Attention이란?
 - Seq2Seq 역시 문장의 길이가 길어지면, Long term dependency 문제로 인해 성능이 저하된다.  
 이를 방지하기 위해서, __사람이 문장을 이해할 때, 문장 중에서 중요한 단어들을 좀 더 강조하여 이해하는 것__ 을 착안해 활용한다.
 
 - 디코딩 타임스텝에서 필요한 정보를 인코더 hidden state에서 가져오기 위해, Context vector(인코더 히든의 가중합)을 만들고 가중치 attention score를 활용한다.
 - 즉, Attention이란 __토큰에 대해 관심 있는 문맥 정보__ 를 끌어오는 알고리즘
 
