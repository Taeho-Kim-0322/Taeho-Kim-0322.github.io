---
layout: post
title:  "PART 3 : 빅데이터 모델링"
date:   2021-03-30 
author: 단우아범
categories: "빅데이터_분석기사"
tags:	
cover:  "/assets/instacode.png"
---

# PART 3 : 빅데이터 모델링


---

## Ch1 : 분석모형 설계  
### 1.1 분석절차 수립

■ 분석모형 선정 

분석 기법 또는 분석 알고리즘을 적용하기 전에 분석 모형에 대한 선정이 필요
분석이 필요한 데이터 속성을 세부적으로 파악, 처리한 뒤에 분석 모형을 선정, 적합한 분석 기법을 선택함
분석모형을 선정하고 설계하는 단계에서 가장 먼저 고려할 점은 어떤 문제를 분석할 것인가, 즉 How가 아니라 What임
분석하고자 하는 문제가 어떤 문제 유형인지에 대해 파악하는 과정이 없다면 분석 모형 선정에 오류가 발생할 수 있음


■ 분석모형 선정 절차

문제 요건 정의 또는 분석 목표 정의
데이터 수집, 정리 및 도식화
데이터 전처리 (데이터 정제, 종속/독립변수 선정, 데이터 변환, 데이터 통합, 데이터 축소 등)
분석모형 선정


■ 분석모형 종류

분석모형은 분석 목표에 따라 데이터 특성을 도출하고, 가설 수립에 따라 전체적인 분석 방향을 정의하는 모형으로
예측 분석 모형, 현황 진단 모형, 최적화 분석 모형 등으로 구분

■ 고려사항 

사전에 분석모형으로 정의, 분석이 실제 추진될 수 있을지 가능성을 타진하는 것이 중요
분석을 진행하기 이전 상황에 맞는  평가 기준표를 작성하여 항목별로 점수를 부여하고 총점을 매긴 후, 분석모형 정의의 가능성을 판별할 수 있음
추진 시급성과 구현 가능성만으로 분석모형 정의를 위한 사전 판별 기준 활용도 가능

※ 분석모형 정의와 판별을 위한 평가 기준표 예시

분석모형 정의에 필요한 데이터가 충분히 확보되어 있는지 판단하며 의사결정 지점으로 가는 과정에서 
분석 기회를 발굴하거나 관련 과거 분석 사례 또는 솔루션을 최대한 활용할 수 있는지 검토한다면 보다 효율적인 분석모형 설계를 진행할 수 있음

분석 시나리오 작성
- 분석 시나리오 작성을 통해 분석 과정과 결과가 어떻게 활용되는지 명확하게 이해할 수 있음
- 데이터 분석 대상 및 범위를 요구사항에 맞게 정의하며 분석을 통해 해결할 수 있는 문제와 목표, 그리고 분석 목표별 구현 모델과 예상결과를 작성함
- 분석 과정에 필요한 데이터, 절차, 분석기법 등의 세부사항을 정의

분석모형 설계
- 분석 대상 및 범위를 정하여 분석 목적을 구현하기 위한 분석 방법론을 설계하는 단계
- 분석모형 설계 시 사전 확인 사항
  * 필요한 데이터 항목이 정해졌는가?
  * 데이터 단위를 고려, 항목에 따른 표준화 방법을 정하였는가?
  * 데이터를 수집한 항목에 따라 단계별로 모델이 설계되었는가?
  * 분석 검증 통계 기법을 선정하였는가?


분석모델링 설계와 검정
- 분석 목적에 기반한 가설 검정 방법
- 추정 방법에 대한 기술 검토 
- 분석 모델링 설계


 분석 모델링에 적합한 알고리즘 설계

모듈 개발 및 테스트

---

### 1.2 분석환경 구축
■ R

통계 계산 및 데이터 마이닝, 시각화를 목적으로 개발된 프로그래밍 언어이면서 오픈소스 소프트웨어
통계 및 그래프 작업을 위한 인터프리터 프로그래밍 언어로, 패키지 개발이 쉬워 통계 소프트웨어 개발에 많이 사용

주요 특징

장단점


RStudio는 R을 위한 오픈소스 통합개발환경(IDE)으로 편리한 분석 개발 인터페이스를 제공


■ 파이썬(Python)

통계를 목적으로 개발된 R과 달리 개발을 목적으로 사용되는 프로그래밍 언어로 오픈소스 소프트웨어
주요특징


장단점



파이썬 아나콘다(Anaconda)는 파이썬 기반의 데이터 분석에 필요한 오픈 소스들의 통합 개발 플랫폼으로
가상환경과 패키지를 관리, 개별 프로젝트 개발 환경을 효율적으로 구성할 수 있음

테스트(Test) 데이터	최종적으로 일반화된 분석 모형을 검증하는 테스트를 위한 데이터




전체 데이터를 학습과 테스트 데이터로 분할할 때는 7:3 또는 8:2의 비율로 진행되며,
학습, 검증, 테스트 데이터로 분할할 때는 4:3:3, 5:3:2, 6:2:2로 분할함
검증 데이터와 테스트 데이터는 모델의 성능을 평가한다는 점에서 비슷해 보이지만, 둘은 확실히 구분해서 사용해야 함
테스트 데이터는 오직 최종 모델의 성능을 평가하기 위해 사용되고, 학습 과정에 전혀 영향을 주지 않음


■ 과대적합(과적합, Overfitting)

모델이 학습 데이터를 과하게 학습하는 것을 의미
일반적으로 학습 데이터에 과접합되면 일반화 성능이 낮아져 이미 학습한 훈련 데이터에 대한 성능은 높게 나오지만,
아직 학습하지 않은 테스트 데이터에 대한 성능은 낮게 나옴 (모델이 학습 데이터에 너무 과하게 맞춰져 일반화하기 어려움)
발생원인
- 학습 데이터에 다양한 샘플 데이터가 포함되지 않을 때
- 모델이 과도하게 복잡할 때 
- 학습 데이터에 노이즈(이상치, 오류값 등)가 다수 포함되어 있을 때
- 파라미터를 과하게 튜닝할 때 
- 변수의 수가 너무 많을 때 
해결방안
- 더 많은 학습 데이터를 이용해 모델을 학습
- 모델의 규제를 가해 모델을 단순화 (대표적으로 L1 규제와 L2 규제가 있음)
- 데이터의 노이즈를 제거
- 파라미터의 수를 줄여 모델을 단순화
- 종속변수에 유의미한 영향을 주는 변수를 선택해 데이터의 차원을 축소
- 검증 데이터를 이용해 과적합 및 일반화 오류의 정도를 측정하고 모델을 개선
     
          ※ 모델 규제(Reularization) : L1 규제(Lasso), L2 규제(Ridge)  https://steadiness-193.tistory.com/262



■ 과소적합(Underfitting)

모델이 너무 단순해서 학습 데이터조차 제대로 예측하지 못하는 경우
모델이 단순하여 데이터 내부의 패턴 또는 규칙을 잘 학습하지 못하는 것
발생원인
- 모델이 너무 단순할 때
- 규제가 너무 강할 때
해결방안
- 종속변수에 영향을 주는 변수의 수를 증가시켜 데이터의 차원을 확장
- 더 많은 파라미터를 사용
- 모델의 규제를 완화
- 다항식 등의 비선형 모델을 사용


■ 검증방법

홀드아웃
- 가장 보편적인 데이터 분할을 통한 검증방법
- 전체 데이터를 랜덤하게 추출해 학습 데이터와 테스트 데이터로 분리하는 방식
- 일반적으로 학습 데이터는 80%, 테스트 데이터는 20%로 구성
- 학습 데이터로 학습하고 테스트 데이터로 모델의 성능이 나아지는 방향으로 튜닝
  그러나, 테스트 데이터를 이용해 모델을 튜닝할 경우 테스트 데이터가 학습에 관여하게 되어 테스트 데이터로 효용이 떨어짐
  학습 데이터를 다시 학습과 검증 데이터로 분리해 학습 데이터 60%, 검증 데이터 20%, 테스트 데이터 20%가 되게 데이터 분할

k-폴드(fold) 교차검증
- 전체 데이터를 무작위로 중복되지 않는 k개의 데이터셋으로 나눈 후, k-1개의 데이터를 학습 데이터로, 나머지 1개를 검증 데이터로 사용하는 방식
- k-폴드 교차검증은 이 과정을 k번 반복해 모든 데이터가 학습과 검증에 사용
- k번의 테스트를 통해 나온 모델의 성능을 평균하여 최종 성능으로 도출
- 모든 데이터셋을 모형 학습과 검증에 사용할 수 있어 특정 데이터셋에 과적합되는 것을 방지할 수 있고, 데이터 부족으로 인한 과소적합 또한 방지
- 홀드아웃보다 다소 느리다는 단점



stratified k-폴드 교차검증
- 주로 분균형 데이터를 분류하는 문제에서 사용하는 방법으로 작동 방식은 k-폴드 교차검증과 동일
  ex. 참인 경우가 1,000개, 거짓인 경우가 10개인 데이터셋의 경우
        k-폴드 교차검증을 사용하면 특정 폴드에는 거짓 데이터가 하나도 포함되지 않을 수 있음
        stratified k-폴드 교차검증은 각 폴드가 가지는 레이블의 분포가 유사하도록 폴드를 추출해 교차검증을 실시

부트스트랩
- 재표본추출(resampling) 방법의 일종으로 중복추출을 허용하는 방법
- 어떤 데이터는 여러 번 추출되어 여러 샘플에 포함되고, 어떤 데이터는 아예 추출되지 않을 수 있음
- 표본 수가 적을 때 효과적



