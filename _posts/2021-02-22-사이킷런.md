---
layout: post
title: "사이킷런"
date: 2021-02-22
author: 단우아범
categories: "머신러닝"
tags:	
cover: "/assets/instacode.png"
---

# 0. Scikit-Learn 소개 
가장 유명한 파이썬의 머신러닝 알고리즘 라이브러리  
사이킷런에서의 데이터 표현 방식을 이해하는 것이 중요한데, 사이킷런에서는 데이터를 데이터 테이블 관점으로 이해하는 것이 중요하다.  
테이블 관점이란, 행과 열로 존재하는 것이며, 행(row)을 표본(samples)이라고 하고, 행의 개수를 n_samples라고 표현함  
열(col)은 특징(feature)라고 하고, 열의 개수를 n_features라고 표현함  

- 특징 배열  
[n_samples, n_features] 모양을 가진 2차원 행렬  
```
x_iris = iris.drop('species', axis=1)
```

- 대상 벡터  
[n_samples, n_target] 모양을 가진 nx1 2차원 행렬
```
y_iris = iris['species']
```



# 1. 사이킷런 API  
사이킷런 Estimator APi를 이용하는 단계는 아래와 같음  
1. 사이킷런으로부터 적정한 Estimator(추정기) 클래스를 임포트해서 모델의 클래스를 선택함  
2. 이 클래스를 원하는 값으로 인스턴스화해서 모델의 하이퍼파라미터를 선택함  
3. 데이터를 특징 배열과 대상 벡터로 배치함  
4. 모델 인스턴스의 fit() 메서드를 호출해 모델을 데이터에 적합시킴  
5. 모델을 새 데이터에 적용함  
  - 지도 학습 : 대체로 predict() 메서드를 사용해 test셋을 적용시킴  
  - 비지도 학습 : transform()이나 predict()를 사용해 데이터 속성을 변환하거나 추론함  
  - 예시  
```
# 1. 모델의 클래스 선택
from sklearn.linear_model import LinearRegression

# 2. 모델의 하이퍼파라미터 선택
# 모델 클래스가 모델 인스턴스와 같지 않음  
model = LinearRegression(~~~)

# 3. 데이터를 특징 배열과 대상 백터로 배치함  

# 4. 모델을 데이터에 적합시킴  
model.fit(X,y)  
# fit() 명령어에는 모델에 종속된 여러 가지 내부 계산이 되따르며, 계산된 결과는 모델 전용 속성에 저장되어 탐색할 수 있음  
# 밑줄 표시(_)가 붙는 것이 특징임  
# e.g. model.coef_, model.intercept_


# 5. 새 데이터에 적용함

```




# 2. 핸즈온머신러닝_2_ch2  
1. 데이터 나누기  
  ```
  from sklearn.model_selection import train_test_split

  train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)
  ```
 - 순수한 무작위 샘플리으 방식은 위와 같음  
 - 데이터 셋이 충분히 크다면 (특성 수에 비해) 일반적으로 괜찮음  
 - 그렇지 않다면, 샘플링 편향이 생길 수 있음  
 - 예를들어, 소득 카테고리의 비율을 고려해서 샘플링 등을 하고 싶을 수 있음  
 
 ```
 housing["income_cat"] = pd.cut(housing["median_income"],
                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],
                               labels=[1, 2, 3, 4, 5])
 
 from sklearn.model_selection import StratifiedShuffleSplit

  split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) #n_splits는 나눌 샘플의 개수 ex_ n_splits = 3이면 train, test 3쌍씩 만듬  
  for train_index, test_index in split.split(housing, housing["income_cat"]):
      strat_train_set = housing.loc[train_index]
      strat_test_set = housing.loc[test_index]
 
 ```
 - np.cut()을 이용해 구간화하고, StratifiedShuffleSplit을 이용해서 구간의 비율을 고려해 샘플링함  


2. 데이터 이해를 위한 탐색과 시각화  
  ```
  housing = strat_train_set.copy() # copy해서 사용하는 것을 추천함
  
  housing.plot(kind="scatter", x="longitude", y="latitude", alpha=0.4,
             s=housing["population"]/100, label="population", figsize=(10,7),
             c="median_house_value", cmap=plt.get_cmap("jet"), colorbar=True,
             sharex=False)
             # 산점도
             #s는 크기, c는 색깔, cmap은 색깔 범위표시, sharex는 x-축의 값과 범례를 표시하지 못하는 버그를 수정함
             
  plt.legend()
  
  ```
  
  ```
  # 상관관계 확인하기
  
  corr_matrix = housing.corr()
  
  # from pandas.tools.plotting import scatter_matrix # 옛날 버전의 판다스에서는
  # 판다스 scatter_matrix로 산점도 & 히스토그램을 그려줌
  from pandas.plotting import scatter_matrix

  attributes = ["median_house_value", "median_income", "total_rooms",
                "housing_median_age"]
  scatter_matrix(housing[attributes], figsize=(12, 8))
  save_fig("scatter_matrix_plot")
  ```
  
  ```
  # 아이디어를 토대로 새로운 파생변수 생성하기
  housing["rooms_per_household"] = housing["total_rooms"]/housing["households"]
  housing["bedrooms_per_room"] = housing["total_bedrooms"]/housing["total_rooms"]
  housing["population_per_household"]=housing["population"]/housing["households"]
  ```

3. 머신러닝 알고리즘을 위한 데이터 준비  


5. 모델 선택과 훈련  
6. 모델 세부 튜닝  
7. 추가 내용  
8. 연습문제 해답  












