---
layout: post
title:  "빅분기_분석기법정리"
date:   2021-04-16 
author: 단우아범
categories: "빅데이터_분석기사"
tags:	
cover:  "/assets/instacode.png"
---

# PART 3 : 빅데이터 모델링


---


## 1.1 분석기법
### 회귀분석
■ 회귀분석 개념

특정 변수가 다른 변수에 어떤 영향을 미치는지, 즉 원인과 결과의 연관을 분석하는 방법으로 주어진 변수들에 대해 변수 사이의 모형을 구하여 적합도를 측정하는 기법
독립변수와 종속변수 간에 선형적인 관계를 도출해 독립변수가 종속변수에 미치는 영향의 정도를 분석하고, 독립변수를 통해 종속변수를 예측하는 분석기법
데이터가 연속형 데이터일 때 사용할 수 있으며 변수 중 범주형 데이터가 있을 때는 더미변수로 변환해 분석해야 함
주어진 데이터가 어떠한 경향성을 띤다는 것을 전제로 회귀방정식을 도출해 회귀선을 추정

■ 회귀분석 가정
 - 선형성
  - 독립변수와 종속변수가 선형적이어야 함
  - 종속변수를 독립변수와 회귀계수의 선형적인 조합으로 표현할 수 있다는 뜻
  - 독립변수가 변화할 때 종속변수가 일정한 크기로 변화한다면 선형성을 만족한다고 볼 수 있음
  - 산점도를 통해 확인할 수 있음
 - 독립성
  - 단순회귀분석에서는 잔차와 독립변수의 값이 서로 독립이어야 함을 의미
  - 다중회귀분석에서는 독립변수 간에 상관성이 없이 독립이어야 함을 의미
 - 등분산성
  - 잔차의 분산이 독립변수와 무관하게 일정해야 함
  - 잔차가 고르게 분포해야 함을 의미
  - 독립변수와 잔차에 대한 산점도를 통해 확인할 수 있음
 - 정규성
  - 잔차항이 정규분포 형태를 띠어야 함
  - 잔차항은 평균이 0이고 분산이 일정한 정규 분포의 형태이어야 함을 의미
  - Q-Q Plot에서 잔차가 우상향하는 직선의 형태를 띠면 정규성을 만족한다고 판단
 - 비상관성
  - 잔차끼리 상관이 없음을 의미
  - 잔차끼리 서로 독립이면 비상관성이 있다고 판단
  - 더비 왓슨(Durbin-Watson) 통계량을 통해 확인 가능


■ 선형 회귀분석
통계적 의미로 종속변수 y와 한 개 이상의 독립변수 x와의 선형 상관성을 파악하는 회귀분석 기법
- 단순선형 회귀분석
  - 가장 단순한 분석으로 한 개의 종속변수 y와 한 개의 독립변수 x로 두 개의 변수사이의 관계를 분석
  - y＝ax＋b, a는 회귀계수, b는 y절편
- 다중선형 회귀분석
  - 하나의 독립변수가 아닌 여러 개의 독립변수를 사용한 회귀분석 기법
  - 단순선형 회귀분석이 독립변수를 하나 가지고 있는 선형회귀분석이라면 다중선형 회귀분석은 독립변수가 두 개 이상이고 종속변수가 y 하나인 선형 회귀분석
  - y＝ax1＋bx2＋...＋c,  (a,b,...)는 회귀계수, c는 y절편

### 로지스틱 회귀분석
■ 로지스틱 회귀분석 개념

회귀분석을 분류에 이용하는 방법으로, 독립변수의 선형결합을 이용해 사건의 발생 가능성을 예측
'어떤 사건이 발생한다 or 발생하지 않는다'를 예측하는 것이 아닌 '어떤 사건이 발생할 확률 or 발생하지 않을 확률'을 예측하여 분류를 진행
일반적으로 사건이 발생할 확률이 50% 이상인 경우 사건이 발생할 것으로 예측하고, 50% 미만인 경우에는 사건이 발생하지 않을 것으로 예측
질병 유무와 같이 종속변수가 이항형 문제일 경우 사용. 보통 질병이 있는 경우를 '1', 없는 경우를 '0'으로 변환해 분석

회귀분석과 마찬가지로 독립변수가 연속형 데이터인 경우에 사용할 수 있으며, 독립변수 중에 범주형 데이터가 있을 경우에는 더미변수로 변환해 분석해야 함

로지스틱 회귀함수식은 각 모수에 대해 비선형식이며, 승산(오즈, odds)으로 로짓변환을 통해 선형함수로 치환이 가능


#### 승산(Odds)와 로짓변환
* 승산(오즈, odds)
   - 확률 p가 주어졌을 때 사건이 발생할 확률이 사건이 발생하지 않을 확률의 몇 배인지에 대한 개념
      odds = (사건이 발생할 확률) / (사건이 발생하지 않을 확률) = p / (1-p)
   - 확률 p가 0에 가까워질수록 오즈 또한 0에 가까워지고, p가 1에 가까워질수록 오즈는 무한대에 가까워짐
   - 오즈값의 범위는 (0, +무한대)

* 로짓변환
   - 회귀분석의 종속변수 y값의 범위는 (-무한대, +무한대)인 것에 반해 로지스틱 회귀분석의 오즈 범위는 (0, +무한대)
     오즈의 범위를 회귀분석과 동일한 (-무한대, +무한대)로 변화하기 위해 사용하는 것이 로짓변환
   - 오즈의 범위를 (-무한대, +무한대)로 변환함으로써 회귀분석을 적용할 수 있음

※ 참고:  https://blog.naver.com/lingua/221526342001


■ 로지스틱 회귀분석 종류

단순 로지스틱 회귀분석: 종속변수가 이항형 문제(범주의 개수가 두 개인 경우)인 회귀분석
다중 로지스틱 회귀분석: 종속변수가 이항형 문제가 아닌 두 개 이상의 범주를 가지게 될 경우의 회귀분석


### 의사결정 트리

■ 의사결정 트리 분석 개념

데이터를 학습하여 데이터 내에 존재하는 규칙을 찾아내고 이 규칙을 나무구조로 모형화해 분류와 예측을 수행하는 분석기법
올바른 분류를 위해서는 상위 노드에서 하위 노드로 갈수록 집단 내에서는 동질성이, 집단 간에는 이질성이 커여야 함
중간 노드가 많다는 말은 규칙이 복잡하다는 이야기이고, 이는 모델이 과적합되기 쉽다는 것을 의미할 수 있음
따라서, 의사결정 트리에서는 과적합이 발생하지 않도록 나무의 깊이를 적절하게 조절해야 함

■ 의사결정 트리 구성
- 뿌리마디(root node) : 나무가 시작되는 마디
- 중간마디(internal node) : 뿌리마다 나온 각 나무줄기 중간에 있는 마디. 끝마디가 아닌 마디로 자식마디가 존재하는 마디
- 끝마디(terminal/leaf node) : 각 나무줄기의 끝에 있는 마디
- 자식마디(child node) : 하나의 마디로부터 분리된 2개 이상의 마디
- 부모마디(parent node) : 자식마디의 상위 마디
- 가지(branch) : 하나의 마디로부터 끝 마디까지 연결된 일련의 마디들
- 깊이(depth) : 가지를 이루는 마디의 수
<img src = "">


■ 의사결정트리 형성

형성 과정
1. 나무의 성장
  - 분석 목적과 자료 구조에 따라 적절한 분리기준과 정지규칙을 설정해 의사결정 트리를 성장시키는 단계
  - 각 마디에서 최적의 분리규칙을 찾아 의사결정 트리를 형성하고 적절한 정지규칙을 만족하면 나무의 성장을 중단
2.가지치기
  - 불필요한 가지를 제거하는 단계로, 분류 오류를 크게 할 위험이 있거나 부적절한 분류기준을 가진 가지를 제거
  - 너무 큰 트리구조는 과적합의 위험이 있고, 너무 작은 트리구조는 과소적합의 위험이 있음
3. 타당성 평가
  - 형성된 의사결정 트리를 평가하는 단계
  - 이익, 비용, 위험 등을 고려하여 모형을 평가하는 단계
  - 검증용 데이터를 이용해 모델의 예측 정확도를 평가하거나, 이익 도표 등의 평가지표를 이용해 의사결정 트리를 평가
4. 해석 및 예측
  - 구축된 의사결정 트리를 예측에 적용하고 이를 해석하는 단계

분리기준
- 하나의 부모마디에서 어떤 입력변수를 입력하여 자식마디들로 분리하는 것이 의사결정 트리 모델의 목표에 가장 잘 부합하는지에 대해 나누는 기준
- 부모마디보다 자식마디의 순수도가 증가, 불순도는 감소하도록 진행


#### 의사결정나무 분리기준
* 이산형 종속변수에 사용되는 분리기준
  - 카이제곱 통계량의 p 값 : p값이 가장 작아지는 방향으로 가지 분할
  - 지니 지수(Gini Index) : 지니 지수가 작을수록 불순도가 낮다는 뜻이므로, 지니 지수가 작아지는 방향으로 가지 분할
  - 엔트로피 지수(Entropy Index) : 엔트로피 지수가 작을수록 불순도가 낮다는 뜻이므로, 엔트로피 지수가 작아지는 방향으로 가지 분할

* 연속형 종속변수에 사용되는 분리기준
  - 분산분석에서의 F 통계량 : F통계량의 p값이 작아지는 방향으로 가지 분할
  - 분산의 감소량 : 분산의 감소량이 커지는 방향으로 가지 분할.

정지규칙
- 더이상 분리가 일어나지 않고 현재의 마디가 끝마디가 되도록 하는 여러 규칙
- 더이상 트리의 분리가 일어나지 않게 하는 규칙
- 의사결정트리를 성장시키는 과정에서 정지규칙을 적용하지 않으면 각 끝마디가 하나의 범주만을 가질 때까지 트리를 성장시키므로 과적합이 발생할 수 있음



 가지치기
- 불필요한 가지를 제거하는 것으로, 나무의 크기가 곧 모형의 복잡도임
- 모형이 너무 복잡할 경우 과적합이 발생할 수 있고 현실 세계에 적용 가능한 적절한 규칙을 발견하기 힘듬
  검증용 데이터를 활용해 예측 정확도를 산출하고 이를 기반으로 불필요한 가지를 제거하거나
  구축된 모형에서 제시되는 규칙들의 타당성을 검토해 타당성이 없는 규칙을 제거하는 식으로 가지치기를 진행
  

■ 의사결정트리 장·단점
  - 장점
    - 트리 구조로 모형이 표현되므로 해석하기 쉬움
    - 이상치에 덜 민감함
    - 수학적 가정이 불필요한 비모수적 모형
    - 변수 선택이 자동적
    - 연속형 변수와 범주형 변수를 모두 처리할 수 있음
  - 단점
    - 분류 기준값의 경계선 부근의 자료 값에 대해서는 오차가 클 수 있음
    - 모형이 너무 복잡할 경우 예측 정확도가 하락하고 해석하기 어려워짐
    - 각 변수의 영향력을 파악하기 힘듬
    - 새로운 자료에 대한 예측이 안정적이지 않을 수 있음


### 인공신경망 분석

■ 인공신경망(ANN: Artificial Neural Network) 분석 개념

인간의 두뇌 신경세포인 뉴런을 기본으로 한 기계학습 기법
입력데이터가 들어가면서 신호의 강도에 따라 가중치 처리되고 활성함수를 통해 출력이 계산되는데,
학습을 거쳐 원하는 결과가 나오게끔 가중치가 조정된다는 점이 주요 특징임
지도학습의 경우 하나의 뉴런은 입력 값(X)과 목표 출력 값(Y)이 있을 때
다음 뉴런으로 전달하는데 적절한 출력 값을 생성하기 위해 가중치 W를 곱한 값에 편향(bias)을 더하여
이를 조정하면서 학습, 최적화 과정을 거치게 되며 최종적으로 활성함수를 활용

■ 인공신경망 주요 요소
- 노드 : 신경계 뉴런, 가중치와 입력값으로 활상함수를 통해 다음 노드로 전달
- 가중치 : 신경계 스냅스, 노드와의 연결계수
- 활성함수 : 임계값을 이용, 노드의 활성화 여부를 결정
- 입력층 : 학습 위한 데이터를 입력
- 은닉층 : 다층 네트워크에서 입력층과 출력층 사이 데이터를 전파학습
- 출력층 : 결과값 출력

#### 활성함수
인경신경망은 노드에 입력되는 값을 바로 다음 노드에 전달하지 않고 비선형 함수에 통과시킨 후 전달, 이때, 사용되는 비선형 함수를 활성함수라고 함.
활성함수는 입력된 값을 적절히 처리해 출력값으로 변환해 줌. 또한, 이를 통해 출력된 값을 다음 노드에서 활성화 할지를 결정.
어떤 활성함수를 사용하느냐에 따라 그 출력값이 달라지므로 적절한 활성함수를 사용하는 것이 중요함. 
대표적인 활성함수로 시그모이드(Sigmoid), 렐루(Relu)가 있음


* 계단(Step) 함수
  - 가장 기본적인 활성함수로 그래프가 계산 모양으로 생겼으며,
    인계값을 기준으로 출력값이 0 혹은 1로 표현
    
* 시그모이드(Sigmoid) 함수
  - 로지스틱 함수라고도 불리며,
 특정 임계값을 기준으로 출력값이 급격하게 변하는 Step함수와 달리 완만한 곡선형태로 0과 1 사이의 값을 출력
 
* 렐루(Relu) 함수 (그래프 있음 p 380, p241)
  - 입력값이 0보다 작으면 0을, 0보다 크면 입력값을 그대로 출력하는 함수
  - Sigmoid 함수보다는 연산이 빠르다는 장점이 있지만, 0보다 작은 값에 대해서는 기울기가 0이므로 뉴런이 작동하지 않을 수 있다는 단점이 있음


■ 인공신경망 분석 장단점
- 장점
  - 잡음에 민감하게 반응하지 않음
  - 비선형적인 문제를 분석하는 데 유용
  - 패턴인식, 분류, 예측 등의 문제에 효과적
  - 스스로 가중치를 학습하므로 다양하고 많은 데이터에 효과적
- 단점
  - 모형이 복잡할 경우 학습에 오랜 시간이 소요
  - 초기 가중치에 따라 전역해가 아닌 지역해로 수렴할 수 있음
  - 추정한 가중치의 신뢰도가 낮음
  - 결과에 대한 해석이 쉽지 않음
  - 은닉층의 수와 은닉 노드의 수를 결정하기 어려움



### 서포트 벡터 머신
■ 서포트 벡터 머신(SVM: Support Vector Machine) 개념

지도학습 기법으로 고차원 또는 무한 차원의 공간에서 초평면(의 집합)을 찾아 이를 이용하여 분류와 회귀를 수행
주어진 데이터를 학습해 새로운 데이터가 어떤 범주에 속할지 결정하는 비확률적 이진 선형 모델을 만듬
두 카테고리 중 어느 하나에 속한 데이터의 집합이 주어졌을 때, 주어진 데이터 집합을 바탕으로 하여
새로운 데이터가 어느 카테고리에 속할지 판단하는 비확률적인 이진 선형 분류 모델을 만드는 기법
서포트 벡터 머신에서는 데이터가 n차원으로 주어졌을 때 이러한 데이터를 n-1차원의 초평면으로 분리함

■ 초평면 & 서프트 벡터
 - 초평면
  - 두 그룹의 점을 구분하는 선
  - 일반적으로 2차원 이상을 처리하고, '초평면'이라는 단어를 사용하면 다차원 공간에서 평면의 개념을 보다 정확하게 전달하기 때문에 '선' 대신 '초평면'이라는 용어를 사용(2차원에서 초평면은 선임)
  - 데이터를 분리하는 초평면은 무수히 많이 존재함. 어떤 초평면을 사용해 데이터를 분리할 지를 결정하는 것이 중요
  - 집단 사이의 마진을 최대화하는 것을 기준으로 데이터에서 가능한 한 먼 결정경계를 학습
 - 서포트 벡터
  - 결정경계에서 가장 가까운 점
<img src = "">

■ 서포트 벡터 머신 특징

기존 분류기가 '오류율 최소화'를 특징으로 한다면 SVM은 '마진 최대화'로 일반화 능력의 극대화를 추구
집단 간의 마진을 최대로 하기 때문에 결정경계에 속하는 데이터가 없고 이로 인해 좀 더 명확한 분류가 가능해짐
마진이 가장 큰 초평면을 분류기(classifier)로 사용할 때, 새로운 자료에 대한 오분류가 가장 낮아짐


■ 서포트 벡터 머신 장단점
- 장점
  - 서포트 벡터만을 이용해 결정경계를 생성하므로 데이터가 희소할 때 효과적
  - 인공신경망보다 과적합의 위험이 적음
  - 노이즈의 영향이 적음
- 단점
  - 데이터셋의 크기가 클 경우 모델링에 많은 시간이 소요
  - 확률 추정치를 반환하지 않고 블랙박스 형태라서 해석하기 어려움
  - 데이터 전처리 과정이 굉장히 중요함

### 연관성 분석
■ 연관성 분석 개념 

상품이나 서비스를 구매하는 등 일련의 거래나 사건 데이터 안에 존재하는 항목 간의 관련성을 파악하는 탐색적 데이터 분석 기법
유사한 개체들을 그룹화하여 각 집단의 특성 파악에 활용되며 사건의 연관규칙을 찾는 기법
목표변수가 불필요한 비지도학습의 한 종류이며, 특정한 분석목표가 없을 때도 사용할 수 있음
주로 거래 내역 데이터의 구매항목 간에 존재하는 연관성에 대한 규칙을 추론하므로 장바구니 분석이라고도 함

■ 연관성 분석 측정지표
- 지지도(support)
  - 전체 거래 중에서 A와 B가 동시에 판매되는 거래의 비율
  - support(A→B) = P(A∩B) = (A와 B를 모두 포함하는 거래 수)/(전체 거래 수)
  - support(A→B)의 값과 support(B→A)의 값이 같고, 값이 1에 가까울수록 연관성이 높다고 할 수 있음
- 신뢰도(confidence)
  - A의 거래 중에서 B가 포함된 거래의 비율로, 상품 간의 존재하는 연관성 정도를 측정하는데 사용
  - confidence(A→B) = P(A∩B)/P(A) = (A와 B를 모두 포함하는 거래 수) / (A를 포함하는 거래 수) 
  - confidence(A→B)의 값과 confidence(B→A)의 값이 다르고, 값이 1에 가까울수록 연관성이 높다고 할 수 있음
- 향상도(lift)
  - A를 구매하지 않았을 때 품목 B를 구매할 확률 대비 A를 구매했을 때 품목 B를 구매할 확률의 증가 비율  
  - lift(A→B) = P(A,B) / P(A)P(B) = (A와 B를 모두 포함하는 거래의 수 * 전체 거래 수)/(A를 포함하는 거래 수 * B를 포함하는 거래수)
  - 향상도가 1이면 두 품목은 서로 독립이고,
  - 1보다 작으면 음의 상관관계로 A를 구매하면 B를 구매하지 않을 확률이 구매할 확률보다 큼을 의미
  - 1보다 크면 양의 상관관계로 임의로 A를 구매한 후 B를 구매할 확률이 큼을 의미


#### 연관성분석 측정 예시
A : 100 / B : 150 / C : 50 / A,B : 300 / A,C : 300 / A,B,C : 100 / 전체거래서 : 1000

→ A를 포함하는 거래수: 800
→ B를 포함하는 거래수: 550
→ A와 B를 모두 포함하는 거래수: 400
→ 지지도(A→B) = 400/1000 = 0.4
→ 신뢰도(A→B) = 400/800 = 0.5
→ 향상도(A→B) = (400*1000)/(800*550) = 0.9

■ apriori 알고리즘 및 절차

모든 항목집합에 대한 지지도를 계산하는 대신 최소 지지도 이상의 빈발 항목집합만을 찾아내서 연관규칙을 계산하는 기법
지지도를 사용해 빈발 아이템 집합을 판별하고 이를 통해 계산의 복잡도를 감소시키는 알고리즘
ex. '품목 A의 지지도가 최소지지도보다 작다면 품목 A를 포함하는 모든 아이템 집합의 지지도는 최소지지도보다 작을 것이다'라는
     아이디어를 바탕으로 품목의 부분집합의 수를 줄임으로써 계산의 복잡도를 감소시킴
최소지지도 이상의 한 항목집단이 빈발(frequent)하다면 이 항목집합의 모든 부분집합은 역시 빈발 항목집합으로 연관 규칙 계산에 포함
최소지지도 미만의 한 항목집단이 비빈발(infrequent)하다면 이 항목집합을 포함하는 모든 집합은 비빈발 항목집합으로 가지치기함
이후 최소신뢰도 기준을 적용해서 최소 신뢰도에 미달하는 연관규칙은 다시 제거하여 반복작업을 수행, 새로운 연관규칙이 없을 때까지 진행


■ 연관성 분석 장단점
- 장점
  - 수많은 상품 간에 존재하는 유의미한 구매 패턴을 발견할 수 있음
  - 목적변수가 없어 특별한 분석 목적 없이도 분석 가능
  - 자료구조와 계산 과정이 간단
  - if A then B의 형태로 원리가 간단해 분석 결과를 이해하기 쉬움
- 단점
  - 품목의 수가 증가함에 따라 필요한 계산량이 기하급수적으로 증가함
  - 거래량이 적은 품목에 대한 규칙 발견이 어려움
  - 연속형 변수를 사용하기 위해서는 몇 개의 구간으로 분할해야 하며
  - 너무 세세하게 분할할 경우 빈도가 적어져 연관 규칙을 발견하기 어려워짐
  - 연관성 분석을 통해 발견되는 규칙의 수가 많아 유의미한 규칙을 찾기 힘듬


### 군집분석
■ 군집분석 개념

관측치들의 유사성(관측치들 사이의 거리)에 기초해 전체 데이터를 몇 개의 집단으로 나누는 분석기법
개체를 분류하기 위한 명확한 기준이 존재하지 않는 경우 사용하는 비지도 학습의 한 방법으로
주어진 각 개체들의 유사성을 분석해서 높은 대상끼리 일반화된 그룹으로 분류하는 기법
군집분류 시 기본적인 가정
- 하나의 군집 내에 속한 개체들의 특성은 동일함
- 군집의 개수 또는 구조와 관계없이 개체간의 거리를 기준으로 분류함
- 개별 군집의 특성은 군집에 속한 개체들의 평균값으로 나타냄
관측치의 유사성을 측정하기 위한 방법으로는 거리 측도와 유사성 측도가 있으며, 대표적인 거리측도로는 유클리드 거리, 맨하튼 거리 등이 있음


■계층적 군집분석

개별 관측치 간의 거리를 계산해서 가장 가까운 관측치부터 결합해 감으로써 계층적 트리 구조를 형성하고 이를 통해 군집화를 수행하는 방법
관측치 간의 거리를 비교하는 것을 기본으로 하므로 대용량 데이터에는 적합하지 않은 방법
군집 간 거리 측정 방법
- 최단연결법: 군집과 군집/데이터 간의 거리 중 최단 값을 거리로 선정
- 최장연결법: 군집과 군집/데이터 간의 거리 중 최장거리 값을 거리로 산정
- 평균연결법: 군집과 군집/데이터 간의 거리의 평균거리 값을 거리로 산정
- 중심연결법: 군집의 중심점 사이의 거리를 거리로 산정
- Ward연결법: 군집 내 편차들의 제곱합을 고려해 군집 내 거리를 기준으로 함


■ 비계층적 군집 분석

계층적으로 군집을 형성하지 않고 구하고자 하는 군집의 수를 사전에 정의해 정해진 군집의 수만큼을 형성하는 방법
많은 양의 데이터를 빠르게 분류할 수 있지만, 군집의 수를 미리 정해줘야 하는데
보통 계층적 군집을 선행해 대략적인 군집을 파악한 후 이를 참고하여 초기 군집 수를 설정함
적은 계산량으로 대규모 DB에서 처리가 유용
대표적으로 K-평균(means) 군집분석, 밀도 기반 클러스터링(DBSCAN: Density Based Spatial Clustering of Applications with Noise),
확률 분포 기반 클러스터링(Gaussian Mixture Model)이 등이 있음



## 1.2 고급 분석기법
