---
layout: post
title:  "PART 1 : 빅데이터 분석 기획"
date:   2020-12-09 
author: 단우아범
categories: "빅데이터_분석기사"
tags:	
cover:  "/assets/instacode.png"
---

# PART 1 : 빅데이터 분석 기획
__한 눈에 보기__  
 - Ch 1 : 빅데이터의 이해
   - 빅데이터의 개요 및 활용
     - 빅데이터 등장 배경, 개념, 특징, 가치, 가치 측정 이슈, 가치 산정 프레임워크, 데이터 산업의 이해, 조직 및 인력
   - 빅데이터 기술 및 제도
     - 빅데이터 플랫폼, 분석 프로세스 절차, 인공지능, 개인정보 법, 제도, 개인정보 활용
    
 - Ch 2 : 데이터 분석 기획
   - 분석 방안 수립
     - 로드맵설정, 문제 정의, 분석 방안
   - 분석 작업 계획
     - 데이터 확보 계획, 분석 절차 및 작업 계획
 - Ch 3 : 데이터 수집 및 저장 계획
   - 데이터 수집 및 전환
     - 데이터 수집 절차, 유형 및 속성 파악, 속성 파악, 변환/통합, 비식별화, 변환 후 품질 검증
   - 데이터 적재와 저장
     - 적재, 저장
   
---

## Ch1 : 빅데이터의 이해
### 빅데이터의 개요 및 활용
  1. 빅데이터의 등장 배경  
    - 빅데이터란 : 기존의 관리 및 분석체계로는 감당할 수 없을 정도의 거대한 데이터의 집합을 지칭  
    - 위키피디아 : __기존 데이터베이스 관리 도구의 데이터 수집, 저장, 관리, 분석의 역량을 넘어서는 대량의 정형 또는 비정형 데이터 세트 및 이러한 데이터로부터 가치를 추출하고 결과를 분석하는 기술__  
    - 국가전략위원회 : 대용량 데이터를 활용 분석하여 가치 있는 정보를 추출하고 생성된 지식을 바탕으로 능동적으로 대응하거나 변화를 예측하기 위한 정보화 기술  
    - 삼성경제연구소 : 기존의 관리 및 분석체계로는 감당할 수 없을 정도의 거대한 데이터의 집합으로 대규모 데이터와 관계된 기술 및 도구를 모두 포함하는 개념  
    - 모바일 스마트 기기 보급의 활성화, 클라우드 서비스, 소셜 미디어의 활용이 일상화되어 정보유통 구조가 새롭게 재편됨에 따라 빅데이터가 각광  
  2. 빅데이터 특징  
    - 규모(Volume), 다양성(Variety), 속도(Velocity) 3V에 더해  
    - 정확성(Veracity), 가치(Value) 총 5V  
  3. 빅데이터의 가치  
    - 맥킨지 : 빅데이터는 `혁신, 경쟁력, 생산성`의 핵심 요소  
    - 가트너 : 데이터는 21세기의 원유이며 미래 경쟁 우위
    - 사회 경제적 가치  
      - 산업의 투명성 증대 : 빅데이터를 시기적절하게 관련 부문에 제공하는 것만으로 검색과 처리시간의 절감 가능  
      - 소비자 니즈 발견, 트렌드 예측, 성과 향상을 위한 실험  
      - 소비자 맞춤형 비즈니스를 위한 고객 세분화  
      - 자동 알고리즘을 통한 의사결정 지원과 대행  
      - 비즈니스 모델, 상품, 서비스 혁신  
    - 사회 경제적 측면에서의 가치 구분  
      - 천연자원 : 데이터의 가치와 가능성, 잠재력, 새로운 원유, 데이터 골드러시, 데이터 금맥찾기  
      - 새로운 재난 : 정보의 범람으로 기회를 파악하기 모호하고 규정 준수가 어려움  
      - 산업적 도구 : 데이터 분석 역량이 기업의 경쟁력, 산업 혁명  
  4. 데이터산업의이해 
    - 넷스케이프의 마크 앤드리슨 : 앞으로는 SW가 모든 산업에 있어 핵심 요소로 작욜할 것  
    - 데이터 산업은  
      - 데이터 처리, 데이터 통합, 데이터 분석, 데이터 연결, 데이터 권리 시대로 진화하고 있음  
      - 데이터 연결 시대 : 4차 산업혁명의 핵심은 DNA(Data, Network, AI)임. 초지능(인간과 유사한 인공지능), 초연결(에지,클라우드 등), 초융합(새로운 방식으로 최적의 사용자 경험을 제공하는 사이버물리시스템)  
  5. 빅데이터 조직 및 인력  
    - 3대 요소, '자원', '기술', '인력'  
    
 
### 빅데이터 기술 및 제도
  1. 빅데이터 플랫폼 : 다양한 데이터 소스에서 수집한 데이터를 분석 처리하여 지식을 추출하고, 이를 기반으로 지능화된 서비스를 제공하는 데 필요한 ICT 환경  
    - 빅데이터 처리 플랫폼 : 데이터 수집, 분석, 처리, 저장 관리, 지식가시화  
    
  2. 빅데이터 분석 프로세스 절차  
    - 1단계 : 빅데이터 수집  
      - 수집 대상 데이터 선정, 세부계획 수립, 수집 실행 3단계  
    - 2단계 : 빅데이터 저장/ 관리  
      - 빅데이터 전처리 : 필터링하거나 유형 변환, 정제  
      - 빅데이터 후처리 : 변환, 통합, 축소 (분석하기 전 용이하도록 가공하는 작업)  
      - 빅데이터 저장 : RDB, NoSQL, 분산 파일시스템 등으로 저장  
    - 3단계 : 빅데이터 처리  
      - 빅데이터 일괄 처리 : 분산처리 시스템 / 하둡의 맵리듀스, MS의 드라이애드(dryad)  
      - 빅데이터 실시간 처리 : '이벤트 기반 실시간 처리 기술', '스트림 처리 기술'  
    - 4단계 : 빅데이터 분석  
      - 분석 계획 수립, 시스템 구축, 실행 3단계  
    - 5단계 : 지식 시각화, 빅데이터 이용  
    - 6단계 : 데이터 폐기  
    
  3. 개인정보법, 제도  
    - 데이터 개인정보보호 가이드라인(2015), 개인정보 비식별 조치 가이드라인(2016), 데이터 3법(2020) 등  
    - 데이터 3법 : 개인정보보호법, 정보통신망법, 신용정보법 3가지 법률을 통칭  

---

## Ch2 : 데이터 분석 계획
### 분석 방안 수립  
  1. 분석 로드맵 설정  
    - 1단계 : 데이터 분석 체계 도입 : 비즈니스 Pain Point를 식별하고 해결해 나가는 관점에서 분석기회를 발굴, 과제를 정의하고 마스터플랜을 수립함  
    - 2단계 : 데이터 분석 유효성 검증 : 분석과제에 대한 Pilot 수행, 설계  
    - 3단계 : 데이터 분석 확산 및 고도화 : 업무 프로세스 내재화, 변화관리, 고도화  
    - 빅데이터 구축 프로세스 : 목표설정 - 계획 수립 - 분석/설계 - 구축 - 테스트  
    
  2. 분석 문제 정의   
  
  3. 데이터 분석 방안  
    - 분석 계획 수립 : 수행 방안을 수립하는 것  
    - 분석 수행 : 수집, 저장, 처리 과정을 거침  
      - 데이터 처리 단계 : 정제(불완전은 채우고, 모순은 수정), 통합(합침), 축소(샘플링 or 차원축소), 변환(로그변환, 정규화 등)  
    - 분석 방안(접근 유형) 설정  
      - 하향식(Top-down) 접근 방법  
        - 해결해야할 이슈나 문제를 먼저 정의하고, 이에 대한 원인진단-해결방안 도출이라는 시나리오를 수립  
        - 분석과정을 단계화하여 각 단계에서 수행될 활동들을 명확히 정의,수행하고 산출물을 점검 확인하여 성공적인 기획활동을 도모하는 방법론  
      - 상향식(Bottom-up) 접근 방법  
        - 다양한 원천으로부터 생성되고 다양한 형태로 존재하는 데이터로부터 문제를 도출하고 통찰력과 지식을 얻는 접근  
      - 프로토타이핑 접근 방법  
        - '원초적 형태'라는 의미로, 요구 사항이나 데이터를 정확히 규정하기 어렵고, 원천도 명확히 파악하기 어려운 상황에서 일단 하고 계속 개선해 나가는 방법  
        - 문제에 대한 인식 수준, 필요 데이터 존재 여부의 불확실성, 데이터 사용 목적의 가변성 때문에 프로토타이핑이 좋음  
      
  
### 분석 작업 계획  
  1. 데이터 확보 계획  
    - 데이터 확보가 매우 중요함  
    - 빅데이터 활용을 위한 두 가지 전제 조건  
      - 데이터를 확보해야 함 : 보다 많은 인풋 채널이 있어야 함  
      - 비즈니스 모델에 대한 발굴  
    - 빅데이터 활용  
    - 빅데이터 구분  
      - 정형화 데이터 : 일정한 규칙을 갖고 체계적으로 정리된 데이터 (테이블)  
      - 반정형화 데이터 : 한글이나 마이크로소프트 워드 등으로 작성된 데이터  (정형화된 텍스트, 마크업 언어(XML), 이메일, EDI 등)  
      - 비정형화 데이터 : 구체적으로 미리 정의된 데이터 모델을 가지고 있지 않은 데이터 (텍스트, 이미지, 음성과 영상, 로그 파일 등)  
    - 능동적 : 데이터를 가지고 있는 주체가 직접 줌, 수동적 : 주체가 공개하면 그걸 가져옴(크롤링 등)  
    
  2. 분석 절차 및 작업 계획  
    - 분석 절차 수립  
      - 관련 데이터 수집 - 데이터 전처리와 정제 - 데이터 분석과 정리 및 처리의 결과 수용 - 해걱과 결과 제시  
 
 
---

## Ch3 : 데이터 수집 및 저장 계획
### 데이터 수집 및 전환
  1. 데이터 수집 절차  
    - 수집 대상 데이터 선정  
      - 가능성, 보안, 정확성, 수집 난이도, 수집 비용 고려함  
    - 수집 세부계획 수립  
      - 정형 데이터 : DBMS, 이진 파일, 반정형 데이터 : 스크립트 파일, 이진 파일, 비정형 파일 : 스크립트 파일(HTTP 프로토콜), 이진 파일(FTP 프로토콜)  
      - 정형 데이터 : ETL, FTP, Open API  
      - 반정형 데이터 : 크롤링, RSS, Open API, FTP  
      - 비정형 데이터 : 크롤링, RSS, Open API, 스트리밍, FTP  
      - 주요 수집 기술들  
        - HTTP 수집 : 크롤링, Open API  
        - FTP 수집  
        - M2M(Machine to Machine) Aggregator 수집 기술  
        - Log Aggregator 수집 기술  
        - RDB Aggregator 수집 기술  
      - 데이터 유형에 따른 수집 기술 활용  
        - RDB 수집 기술 : 스쿱(Sqoop, SQL to Hadoop)  
        - 로그 데이터 : 플룸(Flumne), Scribe, Chukwa / 확장성, 안정성, 유연성, 주기성 고려  
        - 웹 크롤링 : Scrapy   
    - 수집 주기 결정  
      데이터 유형에 따라 배치, 실시간 방식 등을 결정함  
    - 수집계획서 작성  
    - 데이터 수집 실행  
      - 사전 테스트 진행, 수집 시행, 수집 후 처리  
      
  2. 데이터 유형 및 속성 파악  
    데이터 유형은 저장 위치별, 구성 형태별, 존재 형태별로 구분됨  
    - 저장 위치별 : 내부, 외부  
    - 구성 형태별 : 정형, 반정형, 비정형  
    - 존재 형태별 : RDB, 파일 등  
  
  3. 데이터 속성 파악  
    - 전통적 데이터 : 일반적 정형 데이터로 관리  
    - 빅데이터 : 노무라 연구소는 `인재,조직`, `데이터처리,축적,분석 기술`, `데이터(비정형, 정형)`까지 포함하는 광의의 빅데이터를 정의함  
  
  4. 데이터 변환/통합  
    - 필터링 : 중복성, 오류 제거를 위한 필터링 기준  
    - 변환 : 분석에 용이하도록 일관성 있는 형식으로 변환하는 작업  
      - 평활화 : 추세에 벗어나는 값 변환(스무딩), 구간화 or 군집화  
      - 집계 : 데이터 요약  
      - 일반화 : 스케일 변화  
      - 정규화 : 최소-최대 정규화, z-score 정규화, 소수 스케일링 등 적용  
      - 속성 생성 : 주어진 데이터 분포를 대표할 수 있는 새로운 속성/특징 활용(e.g. 지수 등)  
    - 통합 : 출처가 다른 상호 연관성 있는 데이터를 통합함  
    - 축소 : 분석에 불필요한 데이터는 축소  
      - 차원 축소, 데이터 압축, DWT(선형 신호 처리), PCA, 수량 축소 등  
    
  5. 데이터 비식별화  
    1. 데이터 보안과 개인정보보호  
      - 사용자 인증, 접근제어, 데이터 암호화, 개인정보 비식별화 및 개인정보 암호화 등 다양한 기술이 사용됨  
      - 비식별화 처리 기술  
        - 가명 처리 : 주요 식별 요소를 다른 값으로 대체하여 개인 식별을 곤란하게 함  
        - 총계 처리 : 데이터 총합 값을 보임으로써 개별 데이터 값 않보이게 함(태호180cm → CNS 평균 170cm)  
        - 데이터 값 삭제  
        - 범주화  
        - 데이터 마스킹 : 개인 식별하는 데 확률이 높은 식별자를 보이지 않게 처리(김** )  
    2. 개인정보 비식별 조치 기술  
      - 위의 비식별화 처리 기술  
      - 암호화 도구  
        - 동형 암호화  
        - 형태 보존 암호화  
        - 순서 보존 암호화  
      - 향상된 프라이버시 보호 모델  
        - 비식별화  
        - k-익명성 : 공개된 데이터에 대한 연결공격 등 취약점을 방어하기 위해 제안된 프라이버시 보호 모델임, 주어진 데이터 집합에서 같은 값이 적어도 k개 이상 존재하도록 하여 쉽게 다른 정보로 결합할 수 없도록 함    
        - l-다양성 : k-익명성의 취약점을 보완하여, 동질성 곡격 및 배경지식에 의한 공격을 방어하기 위한 모델. 주어진 데이터 집합에서 함께 비식별되는 레코드들은 적어도 l개의 서로 다른 민감한 정보를 가져야 함  
        - t-근접성 : 값의 의미를 고려하는 기법으로, l-다양성의 취약점(쏠림공격, 유사성공격)을 보완하기 위한 모델. 동질 집합에서 특정 정보의 분포와 전체 데이터 집합에서 정보의 분포가 t 이하의 차이를 보여야 함.  
            
  6. 데이터 변환 후 품질 검증  
    1. 데이터 품질 표준화 동향  
      - 대표적인 ISO 8000데이터 품질 표준  
      `- 품질기준  
        - 완전성 : 필수 항목에 누락이 없어야 함  
        - 유일성 : 데이터 항목은 유일해야 하며, 중복되어서는 안됨  
        - 유효성 : 정해진 데이터 유효 범위 및 도메인을 충족해야 함  
        - 일관성 : 데이터가 지켜야 할 구조, 값, 표현되는 형태가 일관되게 정의되고 서로 일치해야 함  
        - 정확성 : 실세계에 존재하는 객체의 표현 값이 정확히 반영되어야 함`  
      - 정형 데이터는 위 품질 기준을 따르고, 비정형 데이터는 다르게 적용되어야 함  
      - 비정형 콘텐츠 자체와 그 메타데이터로 나누어 볼 수 있음  
      - 비정형 데이터 품질 기준 : 기능성, 신뢰성, 사용성, 효율성, 이식성  
      - 품질측정 기준의 선정간 가중치 정의 방법은 사전 정의, 임의적(ad-hoc) 방법이 있음  
      
### 데이터 적재와 
