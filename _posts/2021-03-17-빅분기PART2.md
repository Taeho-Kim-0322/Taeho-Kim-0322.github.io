---
layout: post
title:  "PART 2 : 빅데이터 탐색"
date:   2021-03-17 
author: 단우아범
categories: "빅데이터_분석기사"
tags:	
cover:  "/assets/instacode.png"
---

# PART 2 : 빅데이터 탐색
__한 눈에 보기__  
 - Ch 1 : 데이터 전처리
   - 데이터 전처리
     - 데이터 정제
     - 데이터 결측값 처리
     - 데이터 이상값 처리
     - 분석 변수 처리
    
 - Ch 2 : 데이터 탐색
   - 데이터 탐색 개념
     - 데이터 탐색 개념
     - 기초 통계량
     - 시각화를 통한 탐색적 자료분석
     - 다중공선성
   - 고급 데이터 탐색
     - 시공간 데이터 탐색
     - 다변량 데이터 탐색
     - 비정형 데이터 탐색
 - Ch 3 : 통계 기법 이해
   - 기술통계
     - 데이터 요약
     - 표본추출
     - 확률분포
     - 표본분포
   - 추론통계
     - 점추정
     - 구간추정
     - 가설검정
   
---

## Ch1 :데이터 전처리
### 
---

## Ch2 : 데이터 탐색
### 1.1 데이터 탐색 기초  
#### 데이터 탐색 이해
■ 탐색적 데이터 분석(EDA: Exploratory Data Analysis)  

데이터를 이해하고 의미 있는 관계를 찾아내기 위해 데이터의 통계값과 분포 등을 시각화하고 분석하는 것
수집한 데이터를 다양한 방법을 통해서 관찰하고 이해하는 과정
본격적인 데이터 분석 전에 자료를 직관적인 방법으로 통찰하는 과정

■ 탐색적 데이터 분석 필요성  

데이터 분포 및 값을 검토함으로써 데이터가 표현하는 현상을 이해하며 내재된 잠재적 문제에 대해 인식하고 해결안을 도출할 수 있음
다양한 각도에서 데이터를 살펴보는 과정을 통해 문제정의 단계에서 인지 못한 새로운 양상, 패턴을 발견할 수 있음  

■ 팀색적 데이터 분석 과정 및 절차  

분석의 목적과 변수가 무엇인지, 개별 변수의 이름이나 설명을 가지는지 확인
데이터의 문제성을 확인. 즉, 데이터의 결측치 유무, 이상치 유무 등을 확인
데이터의 개별 속성값이 예상한 범위 분포를 가지는지 확인
관계 속성 확인. 즉, 개별 데이터 간의 속성 관찰에서 보지 못한 데이터 간의 속성을 확인
    

#### 상관관계 분석
■ 상관분석이란  

두 변수가 선형적 관계를 가지는지 분석하는 통계적 분석 방법
두 변수의 선형 관계 정도를 나타내는 척도인 상관계수(Correlation Coefficient)를 사용해 표현
스피어만 상관계수, 켄달 상관계수 등 여러 유형의 상관계수가 있지만, 피어슨 상관계수가 가장 일반적  

■ 상관계수 해석  

상관계수는 -1에서 1 사이의 값을 가지고 강도와 방향의 측면에서 해석
상관계수의 절대값이 클수록 강한 상관이 있음
양의 상관계수: 한 변수의 값이 증가함에 따라 다른 변수의 값도 증가
음의 상관계수: 한 변수의 값이 증가함에 따라 다른 변수의 값은 감소
+1은 완벽한 양의 상관관계, 0은 선형 상관관계 없음, -1은 완벽한 음의 상관관계를 의미  
※ 상관계수가 0.84라면 두 변수는 강한 양의 상관관계가 있다고 해석할 수 있음. 그러나, 0.42보다 2배 강하다는 의미는 아님

#### 기초 통계량 추출 및 이해
자료를 수집하여 요약, 정리하는 기초통계(또는 기술통계)는 자료의 특성을 정량적인 수치에 의하여 나타내는 방법으로,  
중심화 경향(Central Tendency), 퍼짐 정도(산포도), 자료의 분포 형태(Shape of Distribution) 등으로 나타낼 수 있음

■ 중심경향치(중심화 경향 기초통계량)  

산술평균(Arithmetic Mean)
  - 주어진 모든 데이터의 값을 더하여 총합을 구하고, 이를 데이터의 개수로 나눈 것
  - 모평균은 모집단 전체 자료의 산술평균 / 표본평균은 모집단의 부분집합인 추출된 표본 전체의 산술평균
  - 극단치에 민감함
중앙값(Median)
  - 주어진 데이터의 값들을 오름차순 정렬했을 때 중간에 있는 값을 의미
  - 데이터가 홀수인 경우 정확히 중간에 있는 수: (n+1)/2
    데이터가 짝수인 경우 가운데 두 숫자의 산술평균: n/2번째 값과 (n/2)+1번째 값의 산술평균 
  - 평균보다 이상치의 영향을 덜 받기 때문에 이상치가 있는 경우 유용 
최빈값(Mode)
  - 주어진 데이터 중에서 가장 많이 나오는 값
  - 모든 수가 한 번씩 나올 경우 최빈값은 존재하지 않음


■ 산포도(분산도)  

자료의 퍼짐 정도를 나타내는 기초 통계량
중심경향치만으로는 자료의 분포에 대한 충분한 정보를 얻을 수 없으므로 중심경향치에서 자료가 얼마나 떨어져 있는지를 측정하는 척도

범위  
  - 데이터의 최대값에서 최소값을 뺀 것으로 순서통계량의 산포를 의미
사분위수 범위
  - 최소값은 백분위수로 0%, 최대값은 100%, 중앙값은 50% 지점임
    25% 지점에 위치한 값을 Q1(제1사분위수), 75% 지점에 위치한 값을 Q3(제3사분위수)라고 할 때, 사분위수 범위는 Q3에서 Q1을 뺀 값
  ex. <8, 10, 12, 13, 15, 17, 17, 18, 19, 23, 24> 11개의 자료에서 
       Q1 = (11+1)*(25/100) = 3(번째), Q3 = (11+1)*(75/100) = 9(번째)
      따라서, 사분위수 범위는 19 - 12 = 7이 됨
분산
  - 편차의 제곱을 총합하여 평균 낸 값
  - 모든 관측치가 같은 값이면 분산은 0이고, 관측치 간의 차이가 클수록 분산은 커짐
  표준편차
  - 분산 값에 제곱근을 씌운 값 (분산 계산 중에 생긴 단위의 제곱을 원래 단위로 돌리기 위해 제곱근을 취함) 
  
■ 분포 형태  

왜도(Skewness)
  - 분포가 어느 한쪽으로 치우친 정도를 나타내는 통계적 척도
  - 오른쪽으로 더 길면(왼쪽으로 밀집) 양의 값이 되고, 좌우 대칭이면 0, 왼쪽으로 더 길면(오른쪽으로 밀집) 음의 값이 됨
  - <img src = "https://user-images.githubusercontent.com/59005950/111417516-630ae780-8729-11eb-9904-6dc55638ae0d.png">
 
첨도(Kurtosis)
  - 분포의 뾰족한 정도를 나타내는 통계적 척도
  - 첨도가 0보다 크면 정규분포보다 뾰족하고, 첨도가 0이면 정규분포, 첨도가 0보다 작으면 정규분포보다 완만한 분포임 
  - <img src = "https://user-images.githubusercontent.com/59005950/111417518-643c1480-8729-11eb-992c-6e3c262e5b29.png">

#### 시각적 데이터 탐색


### 1.2 고급 데이터 분석  
#### 다변량 데이터 탐색
데이터 분석은 변수의 개수에 따라 크게 일변량 분석, 이변량 분석, 다변량 분석으로 구분  

<img src = "https://user-images.githubusercontent.com/59005950/111417913-1378eb80-872a-11eb-9b51-735cc81be5de.jpg">  

■ 다변량 데이터 탐색  

다차원 척도법(MDS: Multidimensional Scaling)
  - 객체 사이의 유사성 수준을 2차원 또는 3차원 공간에 점으로 시각화하는 분석 기법
  - 거리를 계산하기 위해 유클리드 거리를 주로 활용함
  - 데이터 간의 실제 거리를 근접도로 이용하는 계량형 MDS와 순서 정보를 근접도로 이용하는 비계량형 MDS로 구분

  예) 유럽 21개 도시 거리를 2차원으로 매핑

주성분분석(PCA: Principal Component Analysis)
  - 데이터의 분포를 잘 설명함과 동시에 정보의 손실을 최소화하도록 고차원의 데이터를 저차원의 데이터로 변환하는 차원 축소 분석 기법
  - 여러 변수들의 변량을 '주성분(Principal Component)' 이라는 서로 상관성이 높은 변수들의 선형결합으로 만들어 기존의 상관성이 높은 변수들을 요약, 축소하는 기법
  - 여러 변수들 간에 내재하는 상관관계, 연관성을 이용해 소수의 주성분으로 차원을 축소함으로써 데이터를 이해하기 쉽고 관리하기 쉽게 해줌
  참고. 차원축소와 PCA https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-9-PCA-Principal-Components-Analysis?category=1057680

선형판별분석(LDA: Linear Discriminant Analysis)
  - 다변량 데이터에 판별 함수를 적용해 데이터의 클래스 분리를 최적으로 수행할 수 있게 데이터를 축소함
  - 주성분분석(PCA)은 데이터의 최적 표현의 견지에서 데이터를 축소하는 방법인데 반하여, 선형판별분석(LDA)은 데이터의 최적 분류의 견지에서 데이터를 축소하는 방법
  - 2개 이상의 그룹으로 나누어진 개체에 대해 분류에 영향을 미칠 것 같은 특성(변수)을 측정하고, 이를 이용하여 새로운 개체를 분류하는 방법
  - 데이터의 분포가 정규분포를 따른다는 가정하에 진행되며, 주로 후속 분류 작업 전 차원 축소를 위해 사용

선형판별분석(LDA) 원리

<img src="https://user-images.githubusercontent.com/59005950/111417912-1247be80-872a-11eb-8180-a8478bfb7d7d.png">


파란색 점과 빨간색 점을 서로 분류한다고 했을 때 왼쪽 축과 오른쪽 축 가운데 어떤 것이 더 분류가 잘 되었다고 판단할 수 있을까요?
오른쪽 축입니다. 왼쪽의 데이터들을 축으로 투영(project)했을 때 빨간색과 파란색이 서로 겹치는 부분이 많습니다.
반면, 오른쪽 데이터들을 축으로 사영했을 때 빨간색과 파란색이 명확히 분류가 되었습니다. 

LDA는 바로 오른쪽과 같이 분류를 해주는 기법입니다. 투영 후 두 클래스 간 분산은 최대한 크게 가져가고, 클래스 내부의 분산은 최대한 작게 가져가는 방식입니다.
클래스 간 분산이 최대가 된다는 것은 각 클래스의 중심(평균)이 서로 멀어지도록 분류한다는 것입니다. 클래스 내부의 분산이 작아진다는 것은 
하나의 클래스끼리는 오밀조밀하게 뭉쳐있다는 뜻입니다. 클래스 간 분산이 최대가 되고 클래스 내부 분산이 최소가 되면 [(클래스 간 분산) / (클래스 내부 분산)]은 최대가 됩니다.

다시 말하자면 LDA는 특정 공간상에서 클래스 분리를 최대화하는 축을 찾기 위해 클래스 간 분산(between-class scatter)과
클래스 내부 분산(within-class scatter)의 비율을 최대화하는 방식으로 차원을 축소합니다.

#### 비정형 데이터 탐색
